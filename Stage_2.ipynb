{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDZga8gEGFf4"
      },
      "source": [
        "Stage 2 training on 224*224"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDBEKKEnEq9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0d5b45-ae42-4ddc-a372-6be79f07b708"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAZ07Rs0pg8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7ba956-db91-4ad9-bac1-003b6a1d767f"
      },
      "source": [
        "%cd drive/MyDrive/Project/COVID-19-master"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/148tduUm3_N2YmcWCKycU5qdfNmgLJccA/Project/COVID-19-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPZUIptJ5CQt"
      },
      "source": [
        "# #importing \n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YVqCCFcuBg3"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkudCtj-tNVc",
        "outputId": "db8b05ab-f1a4-41c1-e4ba-315361764db5"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "xtrain_224=np.load('data/x_train.npy')\n",
        "ytrain = np.load('data/y_train.npy')\n",
        "print(\"RUN HOGAYA\")\n",
        "    \n",
        "xtest = np.load('data/x_test.npy')\n",
        "ytest = np.load('data/y_test.npy')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RUN HOGAYA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVxjAl-ytMGr"
      },
      "source": [
        "224 wala"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_UdPn5BtWNK"
      },
      "source": [
        "def confusion_matrix_info(y_true, y_pred, labels=['normal', 'pneumonia',  'COVID-19'],\n",
        "                          title='confusion matrix'):\n",
        "    import seaborn as sns\n",
        "    import pandas as pd\n",
        "    from sklearn.metrics import confusion_matrix, f1_score\n",
        "    import matplotlib.pyplot as plt\n",
        "    C2 = confusion_matrix(y_true, y_pred)\n",
        "    C = pd.DataFrame(C2, columns=labels, index=labels)\n",
        "    m, _ = C2.shape\n",
        "    for i in range(m):\n",
        "        precision = C2[i, i] / sum(C2[:, i])\n",
        "        recall = C2[i, i] / sum(C2[i, :])\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "        print('In class {}:\\t total samples: {}\\t true predict samples: {}\\t'\n",
        "              'acc={:.4f},\\trecall={:.4f},\\tf1-score={:.4f}'.format(\n",
        "            labels[i], sum(C2[i, :]), C2[i, i], precision, recall, f1))\n",
        "    print('-' * 100, '\\n', 'average f1={:.4f}'.format(f1_score(y_true, y_pred, average='micro')))\n",
        " \n",
        "    f, ax = plt.subplots()\n",
        "    sns.heatmap(C, annot=True, ax=ax, cmap=plt.cm.binary)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('predict')\n",
        "    ax.set_ylabel('true')\n",
        "    plt.savefig(title+'.jpg')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXo7r55ftWNK"
      },
      "source": [
        "\n",
        "resnet_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "NUM_CLASSES = 3\n",
        "DENSE_LAYER_ACTIVATION = 'softmax'\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Z7sEgdd2FW"
      },
      "source": [
        "#resnet_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "NUM_CLASSES = 3\n",
        "DENSE_LAYER_ACTIVATION = 'softmax'\n",
        "\n",
        "def Second_keras_model():\n",
        "    model2 = Sequential()\n",
        "\n",
        "    # 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "    # NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
        "    model2.add(ResNet50(include_top = False,input_shape=(224,224,3), pooling = 'avg',weights = resnet_weights_path))\n",
        "    model2.add(BatchNormalization())\n",
        "\n",
        "    # 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
        "    model2.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
        "    model2.load_weights(\"model1.h5\")\n",
        "\n",
        "    # Say not to train first layer (ResNet) model as it is already trained\n",
        "    \n",
        "    return model2"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icGl2kD9Oi5Z"
      },
      "source": [
        "def train(xtrain224, y):\n",
        "    y = tf.keras.utils.to_categorical(y, 3)\n",
        "    #y_test = tf.keras.utils.to_categorical(y_test, 3)\n",
        "    #TRAINING ON 224*224 WITH FREEZED RESNET LAYER\n",
        "    model2 = Second_keras_model()\n",
        "    #print(model2.summary)\n",
        "    model2.layers[0].trainable = False\n",
        "    \n",
        "    print(model2.summary())\n",
        "    opt=tf.keras.optimizers.Adam(lr=0.0001)\n",
        "    model2.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    hist = model2.fit(xtrain224, y, batch_size=32,  epochs=3, verbose=1)\n",
        "\n",
        "\n",
        "    #FINE TUNING ON 224 WITH UNFREEZED RESNET LAYER\n",
        "    model2=model2\n",
        "    model2.layers[0].trainable = True\n",
        "    print(model2.summary())\n",
        "    opt=tf.keras.optimizers.Adam(lr=0.0001)\n",
        "    model2.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    hist = model2.fit(xtrain224, y, batch_size=32,  epochs=5, verbose=1)\n",
        "    model2.save('model2.h5')\n",
        "\n",
        "    y_pred = model3.predict(xtrain224)\n",
        "    confusion_matrix_info(np.argmax(y, axis=1), np.argmax(y_pred, axis=1),title='confusion_matrix_train')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMcHH1qUsSZN"
      },
      "source": [
        "def test(xt, yt):\n",
        "    model = tf.keras.models.load_model('model2.h5')\n",
        "    \n",
        "    y_pred = model.predict(xt)\n",
        "    confusion_matrix_info(yt, np.argmax(y_pred, axis=1),title='confusion_matrix_test')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd0EDNOlOnBg"
      },
      "source": [
        "train(xtrain_224, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Pp2L5HpyqV8c",
        "outputId": "d04e3a96-d1b7-4be9-a27d-f53d9f991be0"
      },
      "source": [
        "test(xtest, ytest)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e20faf082883>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-1aea41d93adf>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(xt, yt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model2.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconfusion_matrix_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'confusion_matrix_test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: model2.h5/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ]
    }
  ]
}