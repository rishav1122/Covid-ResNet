{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Stage1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDpeCRsiF7kV"
      },
      "source": [
        "Stage 1 training on 128*128 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDBEKKEnEq9v",
        "outputId": "baa1dc26-f77b-461b-b34e-64090781413c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAZ07Rs0pg8u",
        "outputId": "4126cb28-e6fc-48eb-ca70-6d724194277e"
      },
      "source": [
        "%cd drive/MyDrive\n",
        "%cd Project/COVID-19-master\n",
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive'\n",
            "/content/drive/.shortcut-targets-by-id/148tduUm3_N2YmcWCKycU5qdfNmgLJccA/Project/COVID-19-master\n",
            "[Errno 2] No such file or directory: 'Project/COVID-19-master'\n",
            "/content/drive/.shortcut-targets-by-id/148tduUm3_N2YmcWCKycU5qdfNmgLJccA/Project/COVID-19-master\n",
            " assets\n",
            " CLR\n",
            " confusion_matrix_test.jpg\n",
            " confusion_matrix_train.jpg\n",
            "'Copy of Rishabmain.py'\n",
            " create_COVIDx.ipynb\n",
            " data\n",
            " Final_weights\n",
            " keras_model.py\n",
            " ktrain-master\n",
            " LICENSE\n",
            " LICENSE.md\n",
            " LRF\n",
            " main.py\n",
            " model_32.h5\n",
            " model.h5\n",
            " Mykeras_model.py\n",
            " my-main.py\n",
            " Mymain.py\n",
            " Naddemmain.py\n",
            " preprocessing.ipynb\n",
            " __pycache__\n",
            " README-lindawangg-2020.3.27.md\n",
            " readme.md\n",
            " resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            " Rishabmain.py\n",
            " test_COVIDx5.txt\n",
            " tmp.hdf5\n",
            " train_COVIDx5.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPZUIptJ5CQt"
      },
      "source": [
        "# # #importing \n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YVqCCFcuBg3"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8yC4E1i_5oD"
      },
      "source": [
        "Load npy files of each sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igRoYtFWOTW-",
        "outputId": "af187cc5-dbe5-4e33-90c6-ea729a942c3f"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "xtrain_128 = np.load('data/x_train_128.npy')\n",
        "print(\"RUN HOGAYA\")\n",
        "ytrain = np.load('data/y_train.npy')\n",
        "    \n",
        "xtest = np.load('data/x_test.npy')\n",
        "ytest = np.load('data/y_test.npy')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RUN HOGAYA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3nkT6VvOgpU"
      },
      "source": [
        "Main code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvcZRAUKsF2O"
      },
      "source": [
        "def confusion_matrix_info(y_true, y_pred, labels=['normal', 'pneumonia',  'COVID-19'],\n",
        "                          title='confusion matrix'):\n",
        "    import seaborn as sns\n",
        "    import pandas as pd\n",
        "    from sklearn.metrics import confusion_matrix, f1_score\n",
        "    import matplotlib.pyplot as plt\n",
        "    C2 = confusion_matrix(y_true, y_pred)\n",
        "    C = pd.DataFrame(C2, columns=labels, index=labels)\n",
        "    m, _ = C2.shape\n",
        "    for i in range(m):\n",
        "        precision = C2[i, i] / sum(C2[:, i])\n",
        "        recall = C2[i, i] / sum(C2[i, :])\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "        print('In class {}:\\t total samples: {}\\t true predict samples: {}\\t'\n",
        "              'acc={:.4f},\\trecall={:.4f},\\tf1-score={:.4f}'.format(\n",
        "            labels[i], sum(C2[i, :]), C2[i, i], precision, recall, f1))\n",
        "    print('-' * 100, '\\n', 'average f1={:.4f}'.format(f1_score(y_true, y_pred, average='micro')))\n",
        " \n",
        "    f, ax = plt.subplots()\n",
        "    sns.heatmap(C, annot=True, ax=ax, cmap=plt.cm.binary)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('predict')\n",
        "    ax.set_ylabel('true')\n",
        "    plt.savefig(title+'.jpg')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFQAuF4LySSs"
      },
      "source": [
        "\n",
        "resnet_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "NUM_CLASSES = 3\n",
        "DENSE_LAYER_ACTIVATION = 'softmax'\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Z7sEgdd2FW"
      },
      "source": [
        "#resnet_weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "NUM_CLASSES = 3\n",
        "DENSE_LAYER_ACTIVATION = 'softmax'\n",
        "\n",
        "def first_keras_model():\n",
        "    model1 = Sequential()\n",
        "\n",
        "    # 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "    # NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
        "    model1.add(ResNet50(include_top = False,input_shape=(128,128,3), pooling = 'avg', weights = resnet_weights_path))\n",
        "    model1.add(BatchNormalization())\n",
        "\n",
        "    # 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
        "    model1.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
        "\n",
        "    # Say not to train first layer (ResNet) model as it is already trained\n",
        "    \n",
        "    return model1\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icGl2kD9Oi5Z"
      },
      "source": [
        "def train(xtrain128, y):\n",
        "    y = tf.keras.utils.to_categorical(y, 3)\n",
        "    \n",
        "    #TRAINING ON 128*128 WITH FREEZED RESNET LAYER\n",
        "    model = first_keras_model()\n",
        "    model=model\n",
        "    model.layers[0].trainable = False\n",
        "    print(model.summary())\n",
        "    opt=tf.keras.optimizers.Adam(lr=0.001)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    hist = model.fit(xtrain128, y, batch_size=32,  epochs=3, verbose=1)\n",
        "\n",
        "\n",
        "    #FINE TUNING ON 128*128 WITH UNFREEZED RESNET LAYER\n",
        "    model.layers[0].trainable = True\n",
        "    print(model.summary())\n",
        "    opt=tf.keras.optimizers.Adam(lr=0.001)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    hist = model.fit(xtrain128, y, batch_size=32,  epochs=5, verbose=1)\n",
        "    model.save('model1.h5')\n",
        "    y_pred = model2.predict(xtrain128)\n",
        "    confusion_matrix_info(np.argmax(y, axis=1), np.argmax(y_pred, axis=1),title='confusion_matrix_train')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMcHH1qUsSZN"
      },
      "source": [
        "def test(xt, yt):\n",
        "    model = tf.keras.models.load_model('model1.h5')\n",
        "    xt = np.load('data/x_test.npy')\n",
        "    yt = np.load('data/y_test.npy')\n",
        "    y_pred = model.predict(xt)\n",
        "    confusion_matrix_info(yt, np.argmax(y_pred, axis=1),title='confusion_matrix_test')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd0EDNOlOnBg",
        "outputId": "9d8ec4ea-7172-4f77-9b33-81851881b645"
      },
      "source": [
        "train(xtrain_128, ytrain)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 6147      \n",
            "=================================================================\n",
            "Total params: 23,602,051\n",
            "Trainable params: 10,243\n",
            "Non-trainable params: 23,591,808\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "437/437 [==============================] - 23s 47ms/step - loss: 0.6877 - accuracy: 0.6964\n",
            "Epoch 2/3\n",
            "437/437 [==============================] - 21s 47ms/step - loss: 0.5479 - accuracy: 0.7797\n",
            "Epoch 3/3\n",
            "437/437 [==============================] - 20s 47ms/step - loss: 0.5195 - accuracy: 0.7916\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 2048)              8192      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 6147      \n",
            "=================================================================\n",
            "Total params: 23,602,051\n",
            "Trainable params: 23,544,835\n",
            "Non-trainable params: 57,216\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            " 60/437 [===>..........................] - ETA: 59s - loss: 1.8138 - accuracy: 0.6713"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Pp2L5HpyqV8c"
      },
      "source": [
        "test(xtest, ytest)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}